{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T09:45:20.574258Z","iopub.status.busy":"2023-05-27T09:45:20.573877Z","iopub.status.idle":"2023-05-27T09:46:24.554892Z","shell.execute_reply":"2023-05-27T09:46:24.553239Z","shell.execute_reply.started":"2023-05-27T09:45:20.574229Z"},"executionInfo":{"elapsed":73825,"status":"ok","timestamp":1684507732533,"user":{"displayName":"張惠恩","userId":"03044690848069314934"},"user_tz":-480},"id":"8fUVDc-Vi5Kv","outputId":"467d447c-ff68-43ec-b8e8-97a4926c5add","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libxtst6\n","Suggested packages:\n","  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n","  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  libxtst6 openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 10 not upgraded.\n","Need to get 28.3 MB of archives.\n","After this operation, 104 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-8-jre-headless amd64 8u372-ga~us1-0ubuntu1~20.04 [28.3 MB]\n","Fetched 28.3 MB in 2s (17.2 MB/s)                 \n","Selecting previously unselected package libxtst6:amd64.\n","(Reading database ... 109859 files and directories currently installed.)\n","Preparing to unpack .../libxtst6_2%3a1.2.3-1_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~20.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~20.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n","Collecting pyspark\n","  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317146 sha256=bd05e8ed2c9f6a6da7e814a4e174cd8784a623f5f4abf4be5aea80db7dfc6f23\n","  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!apt-get -y install openjdk-8-jre-headless\n","!pip install pyspark"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-05-27T09:46:24.558059Z","iopub.status.busy":"2023-05-27T09:46:24.557647Z","iopub.status.idle":"2023-05-27T09:46:30.628078Z","shell.execute_reply":"2023-05-27T09:46:30.626708Z","shell.execute_reply.started":"2023-05-27T09:46:24.558021Z"},"executionInfo":{"elapsed":37923,"status":"ok","timestamp":1684507770453,"user":{"displayName":"張惠恩","userId":"03044690848069314934"},"user_tz":-480},"id":"7XWqH0AWj4ZW","outputId":"c51fb8f9-c351-4b7c-fbb6-5d5124547a9e","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/05/27 09:46:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["#from google.colab import drive\n","import pandas as pd\n","import pyspark\n","from pyspark.sql import SparkSession\n","\n","#link to google drive\n","#drive.mount('/content/gdrive')\n","spark = SparkSession.builder.appName('term project 1').config(\"spark.executor.memory\", \"40G\").config(\"spark.driver.memory\",\"40G\")\\\n","                  .config(\"spark.executor.cores\",\"10\")\\\n","                  .config(\"spark.python.worker.memory\",\"40G\")\\\n","                  .config('spark.plugins','com.nvidia.spark.SQLPlugin')\\\n","                  .getOrCreate()\n","spark.conf.set('spark.rapids.sql.enabled','true')\n","spark.conf.set('spark.rapids.sql.incompatibleOps.enabled', 'true')\n","spark.conf.set('spark.rapids.sql.format.csv.read.enabled', 'true')\n","spark.conf.set('spark.rapids.sql.format.csv.enabled', 'true')\n","spark.conf.set('spark.storage.memotyFraction','true')\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:46:30.630175Z","iopub.status.busy":"2023-05-27T09:46:30.629700Z","iopub.status.idle":"2023-05-27T09:51:34.564609Z","shell.execute_reply":"2023-05-27T09:51:34.563656Z","shell.execute_reply.started":"2023-05-27T09:46:30.630122Z"},"id":"aE5cog7XkEIp","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.sql.functions import monotonically_increasing_id\n","\n","data = spark.read.csv('/kaggle/input/flightdata/itineraries.csv', sep=',', inferSchema=True, header=True)\n","data = data.withColumn(\"index\", monotonically_increasing_id())"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:34.568628Z","iopub.status.busy":"2023-05-27T09:51:34.568181Z","iopub.status.idle":"2023-05-27T09:51:35.050704Z","shell.execute_reply":"2023-05-27T09:51:35.049431Z","shell.execute_reply.started":"2023-05-27T09:51:34.568585Z"},"id":"A1vEPJHZwkOH","trusted":true},"outputs":[],"source":["# import oil and holiday data\n","data_oil = spark.read.csv('/kaggle/input/flightdata/Jet Fuel Spot Price FOB (Dollars per Gallon) (1).csv', sep=',', inferSchema=True, header=True)\n","data_holiday = spark.read.csv('/kaggle/input/flightdata/Holidays (1).csv', sep=',', inferSchema=True, header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##########process itineraries########\n","# drop null and duplicate\n","data = data.na.drop()\n","data = data.na.drop(subset=[\"totalTravelDistance\"])\n","data = data.drop(\"searchDate\").dropDuplicates()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:35.452762Z","iopub.status.busy":"2023-05-27T09:51:35.452355Z","iopub.status.idle":"2023-05-27T09:51:35.469302Z","shell.execute_reply":"2023-05-27T09:51:35.468215Z","shell.execute_reply.started":"2023-05-27T09:51:35.452724Z"},"id":"1oB-UoPdcrG2","trusted":true},"outputs":[],"source":["from pyspark.sql.functions import size, col, udf, struct\n","from pyspark.sql.types import IntegerType, StringType\n","from pyspark.sql.functions import split\n","from datetime import datetime\n","\n","def CountDistinctCol(*args):\n","    count = 0\n","    distinct_list = []\n","    for arg in args:\n","        if arg is not None and arg not in distinct_list :\n","            distinct_list.append(arg)\n","    return len(distinct_list)\n","\n","def getArrivalTime(*args):\n","    arrival_time = None\n","    for arg in reversed(args):\n","        if arg is not None:\n","            dt = datetime.fromisoformat(str(arg))\n","            arrival_time = str(dt.hour) + \":\" + str(dt.minute)\n","            break\n","    return arrival_time\n","\n","def getDeptTime(*args):\n","    dept_time = None\n","    for arg in args:\n","        if arg is not None:\n","            dt = datetime.fromisoformat(str(arg))\n","            dept_time = str(dt.hour) + \":\" + str(dt.minute)\n","            break\n","    return dept_time\n","\n","def SumCol(*args):\n","    total = 0\n","    for arg in args:\n","        if arg is not None:\n","            total += int(arg)\n","    return total\n","\n","CountDistinctCol_Udf = udf(CountDistinctCol, IntegerType())\n","SumCol_Udf = udf(SumCol, IntegerType())\n","getDeptTime_Udf = udf(getDeptTime, StringType())\n","getArrivalTime_Udf = udf(getArrivalTime, StringType())"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:35.471586Z","iopub.status.busy":"2023-05-27T09:51:35.470911Z","iopub.status.idle":"2023-05-27T09:51:36.210250Z","shell.execute_reply":"2023-05-27T09:51:36.209038Z","shell.execute_reply.started":"2023-05-27T09:51:35.471554Z"},"id":"g4JFLyKY0wcT","trusted":true},"outputs":[],"source":["\n","\n","data_airport_count = data.select(\"index\", size(split(col(\"segmentsArrivalAirportCode\"), \"\\\\|\\\\|\")).alias(\"segmentsArrivalAirportCode_Count\"),\\\n","                                              size(split(col(\"segmentsDepartureAirportCode\"), \"\\\\|\\\\|\")).alias(\"segmentsDepartureAirportCode_Count\"))\n","\n","data_additional = data.select(\"index\",\\\n","              split(\"segmentsAirlineCode\", \"\\|\\|\").getItem(0).alias(\"segmentsAirlineCode_1\"),\\\n","              split(\"segmentsAirlineCode\", \"\\|\\|\").getItem(1).alias(\"segmentsAirlineCode_2\"),\\\n","              split(\"segmentsAirlineCode\", \"\\|\\|\").getItem(2).alias(\"segmentsAirlineCode_3\"),\\\n","              split(\"segmentsAirlineCode\", \"\\|\\|\").getItem(3).alias(\"segmentsAirlineCode_4\"),\\\n","              split(\"segmentsAirlineCode\", \"\\|\\|\").getItem(4).alias(\"segmentsAirlineCode_5\"),\\\n","              split(\"segmentsEquipmentDescription\", \"\\|\\|\").getItem(0).alias(\"segmentsEquipmentDescription_1\"),\\\n","              split(\"segmentsEquipmentDescription\", \"\\|\\|\").getItem(1).alias(\"segmentsEquipmentDescription_2\"),\\\n","              split(\"segmentsEquipmentDescription\", \"\\|\\|\").getItem(2).alias(\"segmentsEquipmentDescription_3\"),\\\n","              split(\"segmentsEquipmentDescription\", \"\\|\\|\").getItem(3).alias(\"segmentsEquipmentDescription_4\"),\\\n","              split(\"segmentsEquipmentDescription\", \"\\|\\|\").getItem(4).alias(\"segmentsEquipmentDescription_5\"),\\\n","              split(\"segmentsDurationInSeconds\", \"\\|\\|\").getItem(0).alias(\"segmentsDurationInSeconds_1\"),\\\n","              split(\"segmentsDurationInSeconds\", \"\\|\\|\").getItem(1).alias(\"segmentsDurationInSeconds_2\"),\\\n","              split(\"segmentsDurationInSeconds\", \"\\|\\|\").getItem(2).alias(\"segmentsDurationInSeconds_3\"),\\\n","              split(\"segmentsDurationInSeconds\", \"\\|\\|\").getItem(3).alias(\"segmentsDurationInSeconds_4\"),\\\n","              split(\"segmentsDurationInSeconds\", \"\\|\\|\").getItem(4).alias(\"segmentsDurationInSeconds_5\"),\\\n","              split(\"segmentsCabinCode\", \"\\|\\|\").getItem(0).alias(\"segmentsCabinCode_1\"),\\\n","              split(\"segmentsCabinCode\", \"\\|\\|\").getItem(1).alias(\"segmentsCabinCode_2\"),\\\n","              split(\"segmentsCabinCode\", \"\\|\\|\").getItem(2).alias(\"segmentsCabinCode_3\"),\\\n","              split(\"segmentsCabinCode\", \"\\|\\|\").getItem(3).alias(\"segmentsCabinCode_4\"),\\\n","              split(\"segmentsCabinCode\", \"\\|\\|\").getItem(4).alias(\"segmentsCabinCode_5\"),\\\n","            split(\"segmentsDepartureTimeRaw\", \"\\|\\|\").getItem(0).alias(\"segmentsDepartureTimeRaw_1\"),\\\n","              split(\"segmentsDepartureTimeRaw\", \"\\|\\|\").getItem(1).alias(\"segmentsDepartureTimeRaw_2\"),\\\n","              split(\"segmentsDepartureTimeRaw\", \"\\|\\|\").getItem(2).alias(\"segmentsDepartureTimeRaw_3\"),\\\n","              split(\"segmentsDepartureTimeRaw\", \"\\|\\|\").getItem(3).alias(\"segmentsDepartureTimeRaw_4\"),\\\n","              split(\"segmentsDepartureTimeRaw\", \"\\|\\|\").getItem(4).alias(\"segmentsDepartureTimeRaw_5\"),\\\n","              split(\"segmentsArrivalTimeRaw\", \"\\|\\|\").getItem(0).alias(\"segmentsArrivalTimeRaw_1\"),\\\n","              split(\"segmentsArrivalTimeRaw\", \"\\|\\|\").getItem(1).alias(\"segmentsArrivalTimeRaw_2\"),\\\n","              split(\"segmentsArrivalTimeRaw\", \"\\|\\|\").getItem(2).alias(\"segmentsArrivalTimeRaw_3\"),\\\n","              split(\"segmentsArrivalTimeRaw\", \"\\|\\|\").getItem(3).alias(\"segmentsArrivalTimeRaw_4\"),\\\n","              split(\"segmentsArrivalTimeRaw\", \"\\|\\|\").getItem(4).alias(\"segmentsArrivalTimeRaw_5\"),\\\n","              split(\"flightDate\", \"-\").getItem(0).alias(\"flightYear\").cast(IntegerType()),\\\n","              split(\"flightDate\", \"-\").getItem(1).alias(\"flightMonth\").cast(IntegerType()),\\\n","              split(\"flightDate\", \"-\").getItem(2).alias(\"flightDay\").cast(IntegerType()))\n","\n","\n","columns_to_count = [\"segmentsAirlineCode_1\", \"segmentsAirlineCode_2\",\"segmentsAirlineCode_3\",\"segmentsAirlineCode_4\",\"segmentsAirlineCode_5\",]\n","data_additional = data_additional.withColumn(\"segmentsAirlineCode_Count\", CountDistinctCol_Udf(*data_additional.columns[1:6]))\n","columns_to_count = [\"segmentsEquipmentDescription_1\", \"segmentsEquipmentDescription_2\",\"segmentsEquipmentDescription_3\",\"segmentsEquipmentDescription_4\",\"segmentsEquipmentDescription_5\",]\n","data_additional = data_additional.withColumn(\"segmentsEquipmentDescription_Count\", CountDistinctCol_Udf(*data_additional.columns[6:11]))\n","columns_to_count = [\"segmentsDurationInSeconds_1\", \"segmentsDurationInSeconds_2\",\"segmentsDurationInSeconds_3\",\"segmentsDurationInSeconds_4\",\"segmentsDurationInSeconds_5\",]\n","data_additional = data_additional.withColumn(\"segmentsDurationInSecondse_Count\", SumCol_Udf(*data_additional.columns[11:16]))\n","columns_to_count = [\"segmentsCabinCode_1\", \"segmentsCabinCode_2\",\"segmentsCabinCode_3\",\"segmentsCabinCode_4\",\"segmentsCabinCode_5\",]\n","data_additional = data_additional.withColumn(\"segmentsCabinCode_Count\", CountDistinctCol_Udf(*data_additional.columns[16:21]))\n","columns_to_count = [\"segmentsDepartureTimeRaw_1\", \"segmentsDepartureTimeRaw_2\",\"segmentsDepartureTimeRaw_3\",\"segmentsDepartureTimeRaw_4\",\"segmentsDepartureTimeRaw_5\",]\n","data_additional = data_additional.withColumn(\"DepartureTime\", getDeptTime_Udf(*data_additional.columns[21:26]))\n","columns_to_count = [\"segmentsArrivalTimeRaw_1\", \"segmentsArrivalTimeRaw_2\",\"segmentsArrivalTimeRaw_3\",\"segmentsArrivalTimeRaw_4\",\"segmentsArrivalTimeRaw_5\",]\n","data_additional = data_additional.withColumn(\"ArrivalTime\", getArrivalTime_Udf(*data_additional.columns[26:31]))\n","\n","#data_additional.show(10)\n","#data_additional_test.show(10)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.212289Z","iopub.status.busy":"2023-05-27T09:51:36.211818Z","iopub.status.idle":"2023-05-27T09:51:36.371201Z","shell.execute_reply":"2023-05-27T09:51:36.369763Z","shell.execute_reply.started":"2023-05-27T09:51:36.212246Z"},"trusted":true},"outputs":[],"source":["data_additional = data_additional.withColumn(\"DeptHrs\", split(\"DepartureTime\", \":\").getItem(0).cast(IntegerType()))\\\n","                    .withColumn(\"DeptMin\", split(\"DepartureTime\", \":\").getItem(1).cast(IntegerType()))\\\n","                    .withColumn(\"ArrHrs\", split(\"ArrivalTime\", \":\").getItem(0).cast(IntegerType()))\\\n","                    .withColumn(\"ArrMin\", split(\"ArrivalTime\", \":\").getItem(1).cast(IntegerType()))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.377680Z","iopub.status.busy":"2023-05-27T09:51:36.377051Z","iopub.status.idle":"2023-05-27T09:51:36.511717Z","shell.execute_reply":"2023-05-27T09:51:36.510812Z","shell.execute_reply.started":"2023-05-27T09:51:36.377636Z"},"id":"uPU7pcTt0wmq","trusted":true},"outputs":[],"source":["data_additional = data_additional.select(\"index\", \"segmentsAirlineCode_Count\", \"segmentsEquipmentDescription_Count\", \"segmentsDurationInSecondse_Count\",\"segmentsCabinCode_Count\",\\\n","                                        \"DeptHrs\", \"DeptMin\", \"ArrHrs\", \"ArrMin\",\"flightMonth\",\"flightDay\")\n","data_additional = data_additional.join(data_airport_count, [\"index\"])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.513032Z","iopub.status.busy":"2023-05-27T09:51:36.512679Z","iopub.status.idle":"2023-05-27T09:51:36.614949Z","shell.execute_reply":"2023-05-27T09:51:36.613772Z","shell.execute_reply.started":"2023-05-27T09:51:36.512975Z"},"id":"QEzd_WMDueJP","trusted":true},"outputs":[],"source":["# combine data\n","from pyspark.sql.functions import lit\n","from pyspark.sql.functions import col\n","\n","data_joined = data.join(data_additional, [\"index\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##### for holiday and oil ######\n","def ConvertToDict(list1, list2):\n","  dict_list = {}\n","  for i in range(0, len(list1)):\n","    dict_list[list1[i]] = list2[i]\n","  return dict_list"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.616656Z","iopub.status.busy":"2023-05-27T09:51:36.616236Z","iopub.status.idle":"2023-05-27T09:51:36.623240Z","shell.execute_reply":"2023-05-27T09:51:36.622208Z","shell.execute_reply.started":"2023-05-27T09:51:36.616617Z"},"id":"gEnxfSsS0EOL","trusted":true},"outputs":[],"source":["#########process oil################\n","# convert date in oil to yyyy-mm-dd format\n","from pyspark.sql.functions import to_date, date_format\n","\n","date = to_date(\"Date\", \"MMM dd, yyyy\")\n","data_oil = data_oil.withColumn(\"Date_Formatted\", date_format(to_date(\"Date\", \"MMM dd, yyyy\"), \"yyyy-MM-dd\"))\n","#data_oil.show()\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.625585Z","iopub.status.busy":"2023-05-27T09:51:36.624916Z","iopub.status.idle":"2023-05-27T09:51:36.653576Z","shell.execute_reply":"2023-05-27T09:51:36.651033Z","shell.execute_reply.started":"2023-05-27T09:51:36.625545Z"},"id":"N9s4wcnk-9Bc","trusted":true},"outputs":[],"source":["data_oil = data_oil.filter((data_oil['Date_Formatted'] >= \"2022-04-01\") & (data_oil['Date_Formatted'] < \"2023-01-01\"))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:36.656564Z","iopub.status.busy":"2023-05-27T09:51:36.655857Z","iopub.status.idle":"2023-05-27T09:51:39.271761Z","shell.execute_reply":"2023-05-27T09:51:39.270369Z","shell.execute_reply.started":"2023-05-27T09:51:36.656531Z"},"id":"dtj-U6bYB3b7","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# combine with oil data\n","from pyspark.sql.functions import when\n","\n","oil_date = data_oil.select('Date_Formatted').rdd.flatMap(lambda x : x ).collect()\n","oil_price = data_oil.select('`U.S. Gulf Coast Kerosene-Type Jet Fuel Spot Price FOB (Dollars per Gallon)`').rdd.flatMap(lambda x:x).collect()\n","oil_list = ConvertToDict(oil_date, oil_price)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:39.274193Z","iopub.status.busy":"2023-05-27T09:51:39.273624Z","iopub.status.idle":"2023-05-27T09:51:39.328871Z","shell.execute_reply":"2023-05-27T09:51:39.327706Z","shell.execute_reply.started":"2023-05-27T09:51:39.274149Z"},"id":"yy35AlqyUL-2","trusted":true},"outputs":[],"source":["# fill in missing oil price for date\n","from datetime import datetime\n","\n","idx = pd.date_range('2022-04-01', '2023-01-01')\n","tmp_series = pd.Series(oil_list)\n","tmp_series.index = pd.DatetimeIndex(tmp_series.index)\n","tmp_series = tmp_series.reindex(idx, fill_value=0)\n","\n","\n","prev = 0.0\n","\n","for index, value in tmp_series.items():\n","    if value == 0:\n","      tmp_series._set_value(index, prev)\n","    else:\n","      prev = value\n","\n","tmp_series.index = tmp_series.index.strftime('%Y-%m-%d')\n","\n","# convert series to dict\n","oil_dict = tmp_series.to_dict()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:39.331743Z","iopub.status.busy":"2023-05-27T09:51:39.330923Z","iopub.status.idle":"2023-05-27T09:51:40.342486Z","shell.execute_reply":"2023-05-27T09:51:40.341144Z","shell.execute_reply.started":"2023-05-27T09:51:39.331701Z"},"id":"6_SKnS-790YV","trusted":true},"outputs":[],"source":["from pyspark.sql import functions as F\n","from itertools import chain\n","\n","lookup_map = F.create_map(*[F.lit(x) for x in chain(*oil_dict.items())])\n","lookup_map\n","data_joined = data_joined.withColumn(\"OilPrice\", lookup_map[F.col(\"flightDate\")])\n","\n","#data_joined.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:40.344201Z","iopub.status.busy":"2023-05-27T09:51:40.343778Z","iopub.status.idle":"2023-05-27T09:51:40.392337Z","shell.execute_reply":"2023-05-27T09:51:40.391013Z","shell.execute_reply.started":"2023-05-27T09:51:40.344163Z"},"id":"s491JMv0Z4hT","trusted":true},"outputs":[],"source":["###########process holiday###########\n","# define airport location\n","from pyspark.sql import functions as F\n","from itertools import chain\n","\n","loc_series = pd.Series({\"City of Chicago\":\"ORD\", \"Los Angeles Unified\" : \"LAX\",\"Miami-Dade County\" : \"MIA\",\\\n","                        \"New York City\" : \"JFK\",\"New York City\" : \"LGA\", \"Federal\" : \"all\"})\n","\n","# missing airport\n","# ATL, BOS, CLT, DEN, DFW, DTW, EWR, IAD, OAK, PHL, SFO\n","\n","# convert series to dict\n","airport_dict = loc_series.to_dict()\n","lookup_map = F.create_map(*[F.lit(x) for x in chain(*airport_dict.items())])\n","data_holiday = data_holiday.withColumn(\"Airport\", lookup_map[F.col(\"HolidayType\")])\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:40.394692Z","iopub.status.busy":"2023-05-27T09:51:40.394252Z","iopub.status.idle":"2023-05-27T09:51:40.578175Z","shell.execute_reply":"2023-05-27T09:51:40.577247Z","shell.execute_reply.started":"2023-05-27T09:51:40.394651Z"},"id":"V4nF-JHHPe7Y","trusted":true},"outputs":[],"source":["rdd = data_holiday.rdd.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:40.581415Z","iopub.status.busy":"2023-05-27T09:51:40.580971Z","iopub.status.idle":"2023-05-27T09:51:40.632695Z","shell.execute_reply":"2023-05-27T09:51:40.631357Z","shell.execute_reply.started":"2023-05-27T09:51:40.581373Z"},"id":"-bJG2R2mZ4nw","trusted":true},"outputs":[],"source":["# convert holiday dataframe to dict\n","\n","idx = pd.date_range('2022-01-01', '2023-01-01')\n","tmp_series = pd.Series({\"2022-01-01\" : False})\n","tmp_series.index = pd.DatetimeIndex(tmp_series.index)\n","tmp_series = tmp_series.reindex(idx, fill_value=False)\n","tmp_series.index = tmp_series.index.strftime('%Y-%m-%d')\n","\n","start_date = []\n","end_date = []\n","for row in rdd:\n","    value = row.StartDate.strftime('%Y-%m-%d')\n","    start_date.append(value)\n","    value2 = row.EndDate.strftime('%Y-%m-%d') \n","    end_date.append(value2)\n","\n","for i in range(len(start_date)):\n","  for key in tmp_series.index:\n","      if start_date[i] <= key <= end_date[i]:\n","        #print(key)\n","        tmp_series[key] = True\n","\n","#print(tmp_series)\n","\n","holiday_dict = tmp_series.to_dict()\n","#holiday_dict\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:40.635170Z","iopub.status.busy":"2023-05-27T09:51:40.634699Z","iopub.status.idle":"2023-05-27T09:51:41.664720Z","shell.execute_reply":"2023-05-27T09:51:41.663403Z","shell.execute_reply.started":"2023-05-27T09:51:40.635127Z"},"id":"Ti7-xqMsZ4_I","trusted":true},"outputs":[],"source":["lookup_map = F.create_map(*[F.lit(x) for x in chain(*holiday_dict.items())])\n","data_joined = data_joined.withColumn(\"Holiday\", lookup_map[F.col(\"flightDate\")])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:41.679255Z","iopub.status.busy":"2023-05-27T09:51:41.678817Z","iopub.status.idle":"2023-05-27T09:51:41.686055Z","shell.execute_reply":"2023-05-27T09:51:41.685061Z","shell.execute_reply.started":"2023-05-27T09:51:41.679211Z"},"id":"NapoqDsVliYk","trusted":true},"outputs":[],"source":["#data_joined.write.option(\"header\",True).csv(\"/content/gdrive/MyDrive/data_output.csv\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:41.687809Z","iopub.status.busy":"2023-05-27T09:51:41.687512Z","iopub.status.idle":"2023-05-27T09:51:41.800398Z","shell.execute_reply":"2023-05-27T09:51:41.799229Z","shell.execute_reply.started":"2023-05-27T09:51:41.687783Z"},"trusted":true},"outputs":[],"source":["##### start feature selection ######"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:41.802976Z","iopub.status.busy":"2023-05-27T09:51:41.801592Z","iopub.status.idle":"2023-05-27T09:51:41.865492Z","shell.execute_reply":"2023-05-27T09:51:41.864201Z","shell.execute_reply.started":"2023-05-27T09:51:41.802906Z"},"id":"yrnNk4OAi-vH","trusted":true},"outputs":[],"source":["#data_joined2 = data_joined.filter((data_joined.flightDate >= \"2022-04-15\") & (data_joined.flightDate <= \"2022-06-15\") & (data_joined.index <= 10000))\n","data_joined2, test_cand = data_joined.randomSplit([0.01, 0.9], seed=500)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:41.867177Z","iopub.status.busy":"2023-05-27T09:51:41.866761Z","iopub.status.idle":"2023-05-27T09:51:41.949089Z","shell.execute_reply":"2023-05-27T09:51:41.947898Z","shell.execute_reply.started":"2023-05-27T09:51:41.867138Z"},"id":"5w81TmA8yhHH","trusted":true},"outputs":[{"data":{"text/plain":["[('startingAirport', 'string'),\n"," ('destinationAirport', 'string'),\n"," ('fareBasisCode', 'string'),\n"," ('travelDuration', 'string'),\n"," ('elapsedDays', 'int'),\n"," ('isBasicEconomy', 'boolean'),\n"," ('isRefundable', 'boolean'),\n"," ('isNonStop', 'boolean'),\n"," ('totalFare', 'double'),\n"," ('seatsRemaining', 'int'),\n"," ('segmentsArrivalAirportCode_Count', 'int'),\n"," ('segmentsAirlineCode_Count', 'int'),\n"," ('segmentsAirlineCode_Count', 'int'),\n"," ('segmentsEquipmentDescription_Count', 'int'),\n"," ('segmentsCabinCode_Count', 'int'),\n"," ('OilPrice', 'double'),\n"," ('Holiday', 'boolean'),\n"," ('DeptHrs', 'int'),\n"," ('DeptMin', 'int'),\n"," ('ArrHrs', 'int'),\n"," ('ArrMin', 'int'),\n"," ('flightMonth', 'int'),\n"," ('flightDay', 'int')]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# select features\n","data_selected = data_joined2.select(\"startingAirport\", \"destinationAirport\", \"fareBasisCode\", \"travelDuration\",\"elapsedDays\", \"isBasicEconomy\", \"isRefundable\", \"isNonStop\", \"totalFare\",\\\n","                             \"seatsRemaining\", \"segmentsArrivalAirportCode_Count\", \"segmentsAirlineCode_Count\", \"segmentsAirlineCode_Count\", \\\n","                             \"segmentsEquipmentDescription_Count\", \"segmentsCabinCode_Count\", \"OilPrice\",\"Holiday\", \"DeptHrs\", \"DeptMin\", \"ArrHrs\", \"ArrMin\",\"flightMonth\",\"flightDay\")\n","\n","data_selected.dtypes"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:41.958670Z","iopub.status.busy":"2023-05-27T09:51:41.957633Z","iopub.status.idle":"2023-05-27T09:51:42.092684Z","shell.execute_reply":"2023-05-27T09:51:42.091652Z","shell.execute_reply.started":"2023-05-27T09:51:41.958630Z"},"id":"K4NW_ovTq5wz","trusted":true},"outputs":[],"source":["from pyspark.sql.types import StringType\n","\n","data_selected = data_selected.withColumn(\"isBasicEconomy\",col(\"isBasicEconomy\").cast(StringType()))\\\n","           .withColumn(\"isRefundable\", col(\"isRefundable\").cast(StringType()))\\\n","           .withColumn(\"isNonStop\", col(\"isNonStop\").cast(StringType()))\\\n","           .withColumn(\"Holiday\", col(\"Holiday\").cast(StringType()))\n","\n","#data_selected = data_selected.withColumn(\"isBasicEconomy\", col(\"isBasicEconomy\").cast(StringType()))\\\n","#          .withColumn(\"Holiday\", col(\"Holiday\").cast(StringType()))"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.102678Z","iopub.status.busy":"2023-05-27T09:51:42.101925Z","iopub.status.idle":"2023-05-27T09:51:42.110118Z","shell.execute_reply":"2023-05-27T09:51:42.109223Z","shell.execute_reply.started":"2023-05-27T09:51:42.102643Z"},"id":"f6UDBBhorgys","trusted":true},"outputs":[],"source":["# split dataset to categorical and numerical\n","categorical = [x for (x, dataType) in data_selected.dtypes if dataType == \"string\"]\n","numerical = [x for (x, dataType) in data_selected.dtypes if ((dataType == \"int\") | (dataType == \"double\")) & (x != \"totalFare\")]\n","#print(categorical)\n","#print(numerical)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.112271Z","iopub.status.busy":"2023-05-27T09:51:42.111616Z","iopub.status.idle":"2023-05-27T09:51:42.529976Z","shell.execute_reply":"2023-05-27T09:51:42.529008Z","shell.execute_reply.started":"2023-05-27T09:51:42.112239Z"},"id":"HdtAJx3nrhBC","trusted":true},"outputs":[],"source":["# do one hot encoder on categorical \n","from pyspark.ml.feature import OneHotEncoder, StringIndexer\n","\n","# string indexer transfor string label to index label\n","# create string indexer for each column in categorical\n","string_indexer = [StringIndexer(inputCol=x, outputCol=x+\"_StringIndexer\", handleInvalid=\"skip\") for x in categorical]\n","\n","# encode string index column to one hot encoder column\n","ohe = [OneHotEncoder(inputCols=[f\"{x}_StringIndexer\" for x in categorical],\\\n","                    outputCols=[f\"{x}_OneHotEncoder\" for x in categorical],)]"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.531318Z","iopub.status.busy":"2023-05-27T09:51:42.530926Z","iopub.status.idle":"2023-05-27T09:51:42.536826Z","shell.execute_reply":"2023-05-27T09:51:42.536024Z","shell.execute_reply.started":"2023-05-27T09:51:42.531287Z"},"id":"Z-Kx5OjNrhOv","trusted":true},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","assemblerInput = [x for x in numerical]\n","assemblerInput += [f\"{x}_OneHotEncoder\" for x in categorical]\n","#assemblerInput += [\"flightDate\"]\n","\n","#assemblerInput"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.538613Z","iopub.status.busy":"2023-05-27T09:51:42.538117Z","iopub.status.idle":"2023-05-27T09:51:42.562145Z","shell.execute_reply":"2023-05-27T09:51:42.561146Z","shell.execute_reply.started":"2023-05-27T09:51:42.538583Z"},"id":"08ueyXRgr7t4","trusted":true},"outputs":[],"source":["vector_assembler = VectorAssembler(inputCols=assemblerInput, outputCol=\"VectorAssembler_feature\", handleInvalid='skip')\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.564071Z","iopub.status.busy":"2023-05-27T09:51:42.563516Z","iopub.status.idle":"2023-05-27T09:51:42.568752Z","shell.execute_reply":"2023-05-27T09:51:42.567884Z","shell.execute_reply.started":"2023-05-27T09:51:42.564040Z"},"id":"xAxvUTbpDHZm","trusted":true},"outputs":[],"source":["# define stage for pipeline\n","stages = []\n","stages += string_indexer \n","stages += ohe \n","stages += [vector_assembler]"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-05-27T09:51:42.570956Z","iopub.status.busy":"2023-05-27T09:51:42.569862Z","iopub.status.idle":"2023-05-27T09:51:42.698089Z","shell.execute_reply":"2023-05-27T09:51:42.696920Z","shell.execute_reply.started":"2023-05-27T09:51:42.570901Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.classification import LogisticRegression\n","\n","lr = LogisticRegression(maxIter=10, regParam=0.01, labelCol=\"Delay\", featuresCol='VectorAssembler_feature')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-05-27T09:51:42.736019Z","iopub.status.busy":"2023-05-27T09:51:42.735213Z"},"executionInfo":{"elapsed":2700978,"status":"error","timestamp":1684512466619,"user":{"displayName":"張惠恩","userId":"03044690848069314934"},"user_tz":-480},"id":"4JKx6ZNTDdtX","outputId":"0ed90ad9-156b-45d8-8b20-ffe6ec6906f8","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["23/05/27 09:51:43 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","[Stage 63:==========================================>           (157 + 4) / 200]\r"]}],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.feature import MinMaxScaler\n","\n","scaler = MinMaxScaler(inputCol=\"VectorAssembler_feature\", outputCol=\"feature_scaled\", min=0, max=100)\n","pipeline = Pipeline(stages = stages + [scaler])\n","pipeline_model = pipeline.fit(data_selected)\n","#data_transformed = pipeline_model.transform(d_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_transformed = pipeline_model.transform(data_selected)\n","#data_transformed.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#get only vector feature and label\n","data_transformed_final = data_transformed.select(\"feature_scaled\",\"totalFare\")\n","#data_transformed_final.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["###### feature selected by ml ######\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from  pyspark.ml.evaluation import RegressionEvaluator\n","\n","classifier = RandomForestRegressor(labelCol=\"totalFare\", featuresCol='feature_scaled')\n","paramGrid = (ParamGridBuilder()\\\n","            .addGrid(classifier.maxDepth, [2, 5, 10])\n","            .addGrid(classifier.maxBins, [5, 10 , 20])\n","            .addGrid(classifier.numTrees,[5, 20, 50])\n","            .build())\n","crossval = CrossValidator(estimator=classifier,\n","                         estimatorParamMaps=paramGrid,\n","                         evaluator=RegressionEvaluator(labelCol='totalFare', predictionCol='prediction', metricName='mse'),\n","                         numFolds=2)\n","fitModel = crossval.fit(data_transformed_final)\n","BestModel= fitModel.bestModel\n","featureImportances= BestModel.featureImportances.toArray()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot importance of feature\n","import matplotlib.pyplot as plt\n","\n","x_values = list(range(len(featureImportances)))\n","plt.figure(figsize=(20,10));\n","plt.bar(x_values, featureImportances, orientation = 'vertical')\n","feature_list = [\"startingAirport\", \"destinationAirport\", \"fareBasisCode\", \"travelDuration\",\"elapsedDays\", \"isBasicEconomy\", \"isRefundable\", \"isNonStop\",\n","                 \"seatsRemaining\", \"segmentsArrivalAirportCode_Count\", \"segmentsAirlineCode_Count\", \"segmentsAirlineCode_Count\",\n","                 \"segmentsEquipmentDescription_Count\", \"segmentsCabinCode_Count\", \"OilPrice\",\"Holiday\", \"DeptHrs\", \"DeptMin\", \"ArrHrs\", \"ArrMin\",\"flightMonth\",\"flightDay\"]\n","plt.xticks(x_values, feature_list, rotation=90)\n","plt.ylabel('Importance')\n","plt.xlabel('Feature')\n","plt.title('Feature Importances');"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"id":"CNZdU9KhyhXQ","trusted":true},"outputs":[],"source":["#for n in range(10, maximum, 10):\n"," #   print(\"Testing top n= \", n, \" features\")\n","    \n","#best_n_features= featureImportances.argsort()[-10:][::-1]\n","#best_n_features= best_n_features.tolist()\n","\n","\n","\n","#### need to save vs\n","#vs= VectorSlicer(inputCol='features',   outputCol='best_features',indices=best_n_features)\n","#bestFeaturesDf= vs.transform(final_data)\n","\n","'''    vs= VectorSlicer(inputCol='features',   outputCol='best_features',indices=best_n_features)\n","    bestFeaturesDf= vs.transform(final_data)\n","    train,test= bestFeaturesDf.randomSplit([0.7, 0.3])\n","    \n","    columns = ['Classifier', 'Result']\n","    vals = [('Place Holder', 'N/A')]\n","    results = spark.createDataFrame(vals, columns)\n","    paramGrid = (ParamGridBuilder()\\\n","            .addGrid(classifier.maxDepth, [2, 5, 10])\n","            .addGrid(classifier.maxBins, [5, 10 , 20])\n","            .addGrid(classifier.numTrees,[5, 20, 50])\n","            .build())\n","crossval = CrossValidator(estimator=classifier,\n","                         estimatorParamMaps=paramGrid,\n","                         evaluator=MulticlassClassificationEvaluator(),\n","                         numFolds=2)\n","fitModel = crossval.fit(train)\n","BestModel= fitModel.bestModel\n","    featureImportances= BestModel.featureImportances.toArray()\n","    print(\"Feature Importances: \", featureImportances)\n","predictions = fitModel.transform(test)\n","accuracy = (MC_evaluator.evaluate(predictions))*100\n","print(\" \")\n","print(\"Accuracy: \", accuracy)\n","'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYCUMmlf8B7B"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFcbcfY78CAf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibk8gAqb8CHF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpV7G68NB3q-"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOigdGzVe2iFq1Eq4cCD8F9","gpuType":"T4","provenance":[{"file_id":"1yeHb5jtKyalBTkcALa9h5nPF9ld84FUT","timestamp":1684425871920}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
